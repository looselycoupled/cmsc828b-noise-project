{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J0Qjg6vuaHNt"
   },
   "source": [
    "# Transformer model for language understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JjJJyJTZYebt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tf-nightly in /Users/allen/.pyenv/versions/3.7.2/envs/cmsc828b/lib/python3.7/site-packages (2.2.0.dev20200319)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /Users/allen/.pyenv/versions/3.7.2/envs/cmsc828b/lib/python3.7/site-packages (from tf-nightly) (3.11.3)\n",
      "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /Users/allen/.pyenv/versions/3.7.2/envs/cmsc828b/lib/python3.7/site-packages (from tf-nightly) (1.4.1)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /Users/allen/.pyenv/versions/3.7.2/envs/cmsc828b/lib/python3.7/site-packages (from tf-nightly) (0.34.2)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /Users/allen/.pyenv/versions/3.7.2/envs/cmsc828b/lib/python3.7/site-packages (from tf-nightly) (1.27.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /Users/allen/.pyenv/versions/3.7.2/envs/cmsc828b/lib/python3.7/site-packages (from tf-nightly) (0.2.0)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /Users/allen/.pyenv/versions/3.7.2/envs/cmsc828b/lib/python3.7/site-packages (from tf-nightly) (2.10.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/allen/.pyenv/versions/3.7.2/envs/cmsc828b/lib/python3.7/site-packages (from tf-nightly) (1.14.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /Users/allen/.pyenv/versions/3.7.2/envs/cmsc828b/lib/python3.7/site-packages (from tf-nightly) (1.1.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /Users/allen/.pyenv/versions/3.7.2/envs/cmsc828b/lib/python3.7/site-packages (from tf-nightly) (1.6.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/allen/.pyenv/versions/3.7.2/envs/cmsc828b/lib/python3.7/site-packages (from tf-nightly) (3.2.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/allen/.pyenv/versions/3.7.2/envs/cmsc828b/lib/python3.7/site-packages (from tf-nightly) (1.1.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /Users/allen/.pyenv/versions/3.7.2/envs/cmsc828b/lib/python3.7/site-packages (from tf-nightly) (0.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /Users/allen/.pyenv/versions/3.7.2/envs/cmsc828b/lib/python3.7/site-packages (from tf-nightly) (1.12.1)\n",
      "Requirement already satisfied: tf-estimator-nightly in /Users/allen/.pyenv/versions/3.7.2/envs/cmsc828b/lib/python3.7/site-packages (from tf-nightly) (2.3.0.dev2020032201)\n",
      "Requirement already satisfied: gast==0.3.3 in /Users/allen/.pyenv/versions/3.7.2/envs/cmsc828b/lib/python3.7/site-packages (from tf-nightly) (0.3.3)\n",
      "Requirement already satisfied: tb-nightly<2.3.0a0,>=2.2.0a0 in /Users/allen/.pyenv/versions/3.7.2/envs/cmsc828b/lib/python3.7/site-packages (from tf-nightly) (2.2.0a20200322)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /Users/allen/.pyenv/versions/3.7.2/envs/cmsc828b/lib/python3.7/site-packages (from tf-nightly) (1.18.1)\n",
      "Requirement already satisfied: setuptools in /Users/allen/.pyenv/versions/3.7.2/envs/cmsc828b/lib/python3.7/site-packages (from protobuf>=3.8.0->tf-nightly) (46.1.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/allen/.pyenv/versions/3.7.2/envs/cmsc828b/lib/python3.7/site-packages (from tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (3.2.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/allen/.pyenv/versions/3.7.2/envs/cmsc828b/lib/python3.7/site-packages (from tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (1.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/allen/.pyenv/versions/3.7.2/envs/cmsc828b/lib/python3.7/site-packages (from tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (2.23.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /Users/allen/.pyenv/versions/3.7.2/envs/cmsc828b/lib/python3.7/site-packages (from tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (1.11.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/allen/.pyenv/versions/3.7.2/envs/cmsc828b/lib/python3.7/site-packages (from tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (0.4.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/allen/.pyenv/versions/3.7.2/envs/cmsc828b/lib/python3.7/site-packages (from tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (1.6.0.post2)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/allen/.pyenv/versions/3.7.2/envs/cmsc828b/lib/python3.7/site-packages (from requests<3,>=2.21.0->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/allen/.pyenv/versions/3.7.2/envs/cmsc828b/lib/python3.7/site-packages (from requests<3,>=2.21.0->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (2.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/allen/.pyenv/versions/3.7.2/envs/cmsc828b/lib/python3.7/site-packages (from requests<3,>=2.21.0->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (2019.11.28)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/allen/.pyenv/versions/3.7.2/envs/cmsc828b/lib/python3.7/site-packages (from requests<3,>=2.21.0->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (1.25.8)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /Users/allen/.pyenv/versions/3.7.2/envs/cmsc828b/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/allen/.pyenv/versions/3.7.2/envs/cmsc828b/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/allen/.pyenv/versions/3.7.2/envs/cmsc828b/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (4.0.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/allen/.pyenv/versions/3.7.2/envs/cmsc828b/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (1.3.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Users/allen/.pyenv/versions/3.7.2/envs/cmsc828b/lib/python3.7/site-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/allen/.pyenv/versions/3.7.2/envs/cmsc828b/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tf-nightly\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from functools import partial\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fd1NWMxjfsDd"
   },
   "source": [
    "## Setup input pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t4_Qt8W1hJE_"
   },
   "source": [
    "Use [TFDS](https://www.tensorflow.org/datasets) to load the [Portugese-English translation dataset](https://github.com/neulab/word-embeddings-for-nmt) from the [TED Talks Open Translation Project](https://www.ted.com/participate/translate).\n",
    "\n",
    "This dataset contains approximately 50000 training examples, 1100 validation examples, and 2000 test examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GQ5pUdkOIXME"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<FlatMapDataset shapes: (<unknown>, <unknown>), types: (tf.string, tf.string)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load(file1, file2):\n",
    "    data = []\n",
    "    with open(file1, \"r\") as f1:\n",
    "        with open(file2, \"r\") as f2:\n",
    "            while True:\n",
    "                try:\n",
    "                    yield (\n",
    "                        tf.constant(next(f1)), \n",
    "                        tf.constant(next(f2)), \n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    return data\n",
    "                    \n",
    "\n",
    "from functools import partial\n",
    "\n",
    "loader = partial(load, 'data/baseline.50000.tok.de', 'data/baseline.50000.tok.en')\n",
    "        \n",
    "train_examples = tf.data.Dataset.from_generator(\n",
    "    loader,\n",
    "    (tf.string, tf.string),\n",
    ")\n",
    "train_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cK12ssHsIW4I"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<FlatMapDataset shapes: (<unknown>, <unknown>), types: (tf.string, tf.string)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = partial(load, 'data/baseline.val.tok.de', 'data/baseline.val.tok.en')\n",
    "        \n",
    "val_examples = tf.data.Dataset.from_generator(\n",
    "    loader,\n",
    "    (tf.string, tf.string),\n",
    ")\n",
    "val_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RCEKotqosGfq"
   },
   "source": [
    "Create a custom subwords tokenizer from the training dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KVBg5Q8tBk5z",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "CPU times: user 3min 52s, sys: 4.49 s, total: 3min 56s\n",
      "Wall time: 3min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenizer_en = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
    "    (en.numpy() for pt, en in train_examples), target_vocab_size=2**13)\n",
    "\n",
    "tokenizer_pt = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
    "    (pt.numpy() for pt, en in train_examples), target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o9KJWJjrsZ4Y"
   },
   "source": [
    "The tokenizer encodes the string by breaking it into subwords if the word is not in its dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bcRp7VcQ5m6g"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 20000\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kGi4PoVakxdc"
   },
   "source": [
    "Add a start and end token to the input and target. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UZwnPr4R055s"
   },
   "outputs": [],
   "source": [
    "def encode(lang1, lang2):\n",
    "  lang1 = [tokenizer_pt.vocab_size] + tokenizer_pt.encode(\n",
    "      lang1.numpy()) + [tokenizer_pt.vocab_size+1]\n",
    "\n",
    "  lang2 = [tokenizer_en.vocab_size] + tokenizer_en.encode(\n",
    "      lang2.numpy()) + [tokenizer_en.vocab_size+1]\n",
    "  \n",
    "  return lang1, lang2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tx1sFbR-9fRs"
   },
   "source": [
    "You want to use `Dataset.map` to apply this function to each element of the dataset.  `Dataset.map` runs in graph mode.\n",
    "\n",
    "* Graph tensors do not have a value. \n",
    "* In graph mode you can only use TensorFlow Ops and functions. \n",
    "\n",
    "So you can't `.map` this function directly: You need to wrap it in a `tf.py_function`. The `tf.py_function` will pass regular tensors (with a value and a `.numpy()` method to access it), to the wrapped python function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mah1cS-P70Iz"
   },
   "outputs": [],
   "source": [
    "def tf_encode(pt, en):\n",
    "  result_pt, result_en = tf.py_function(encode, [pt, en], [tf.int64, tf.int64])\n",
    "  result_pt.set_shape([None])\n",
    "  result_en.set_shape([None])\n",
    "\n",
    "  return result_pt, result_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2QEgbjntk6Yf"
   },
   "outputs": [],
   "source": [
    "# Note: To keep this example small and relatively fast, drop examples with a length of over 40 tokens.\n",
    "MAX_LENGTH = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c081xPGv1CPI"
   },
   "outputs": [],
   "source": [
    "def filter_max_length(x, y, max_length=MAX_LENGTH):\n",
    "  return tf.logical_and(tf.size(x) <= max_length,\n",
    "                        tf.size(y) <= max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u7SiL41mbiCZ"
   },
   "outputs": [],
   "source": [
    "train_preprocessed = (\n",
    "    train_examples\n",
    "    .map(tf_encode) \n",
    "    .filter(filter_max_length)\n",
    "    # cache the dataset to memory to get a speedup while reading from it.\n",
    "    .cache()\n",
    "    .shuffle(BUFFER_SIZE))\n",
    "\n",
    "val_preprocessed = (\n",
    "    val_examples\n",
    "    .map(tf_encode)\n",
    "    .filter(filter_max_length))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7oo6Z4xUcMmt"
   },
   "source": [
    "Pad and batch examples together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9mk9AZdZ5bcS"
   },
   "outputs": [],
   "source": [
    "# train_dataset = (train_preprocessed\n",
    "#                  .padded_batch(BATCH_SIZE, padded_shapes=([None], [None]))\n",
    "#                  .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "\n",
    "# val_dataset = (val_preprocessed\n",
    "#                .padded_batch(BATCH_SIZE,  padded_shapes=([None], [None])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vpLOt3T9WtKo"
   },
   "source": [
    "Note: As of **TensorFlow 2.2** the padded_shapes argument is no longer required. The default behavior is to pad all axes to the longest in the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ByTGAOY3XSyo"
   },
   "outputs": [],
   "source": [
    "train_dataset = (train_preprocessed\n",
    "                 .padded_batch(BATCH_SIZE)\n",
    "                 .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "\n",
    "val_dataset = (val_preprocessed\n",
    "               .padded_batch(BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2r32dOx4XVHP"
   },
   "source": [
    "Get an batch from the validation set to test the code on later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_fXvfYVfQr2n"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(64, 40), dtype=int64, numpy=\n",
       " array([[8193,   33, 5034, ...,  328,    3, 8194],\n",
       "        [8193, 1849,  958, ..., 8194,    0,    0],\n",
       "        [8193,   52, 1843, ...,    3, 8194,    0],\n",
       "        ...,\n",
       "        [8193,  107,  211, ...,    0,    0,    0],\n",
       "        [8193, 3528, 3481, ...,    0,    0,    0],\n",
       "        [8193,   33,  107, ...,    0,    0,    0]])>,\n",
       " <tf.Tensor: shape=(64, 39), dtype=int64, numpy=\n",
       " array([[8242,   27, 4084, ...,  776,    3, 8243],\n",
       "        [8242, 2236,    2, ..., 8101,    3, 8243],\n",
       "        [8242,   37, 1256, ..., 8243,    0,    0],\n",
       "        ...,\n",
       "        [8242,   26,   96, ...,    0,    0,    0],\n",
       "        [8242, 4090,    2, ...,    0,    0,    0],\n",
       "        [8242, 7553,    1, ...,    0,    0,    0]])>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_batch, en_batch = next(iter(val_dataset))\n",
    "pt_batch, en_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nBQuibYA4n0n"
   },
   "source": [
    "## Positional encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WhIOZjMNKujn"
   },
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "  return pos * angle_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Rz82wEs5biZ"
   },
   "outputs": [],
   "source": [
    "def positional_encoding(position, d_model):\n",
    "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model)\n",
    "  \n",
    "  # apply sin to even indices in the array; 2i\n",
    "  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "  \n",
    "  # apply cos to odd indices in the array; 2i+1\n",
    "  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "    \n",
    "  pos_encoding = angle_rads[np.newaxis, ...]\n",
    "    \n",
    "  return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1kLCla68EloE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50, 512)\n"
     ]
    }
   ],
   "source": [
    "pos_encoding = positional_encoding(50, 512)\n",
    "print (pos_encoding.shape)\n",
    "\n",
    "plt.pcolormesh(pos_encoding[0], cmap='RdBu')\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0, 512))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a_b4ou4TYqUN"
   },
   "source": [
    "## Masking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s42Uydjkv0hF"
   },
   "source": [
    "Mask all the pad tokens in the batch of sequence. It ensures that the model does not treat padding as the input. The mask indicates where pad value `0` is present: it outputs a `1` at those locations, and a `0` otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U2i8-e1s8ti9"
   },
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "  \n",
    "  # add extra dimensions to add the padding\n",
    "  # to the attention logits.\n",
    "  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A7BYeBCNvi7n"
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# x = tf.constant([[7, 6, 0, 0, 1], [1, 2, 3, 0, 0], [0, 0, 0, 4, 5]])\n",
    "# create_padding_mask(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z0hzukDBgVom"
   },
   "source": [
    "The look-ahead mask is used to mask the future tokens in a sequence. In other words, the mask indicates which entries should not be used.\n",
    "\n",
    "This means that to predict the third word, only the first and second word will be used. Similarly to predict the fourth word, only the first, second and the third word will be used and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dVxS8OPI9uI0"
   },
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(size):\n",
    "  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "  return mask  # (seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yxKGuXxaBeeE"
   },
   "outputs": [],
   "source": [
    "# x = tf.random.uniform((1, 3))\n",
    "# temp = create_look_ahead_mask(x.shape[1])\n",
    "# temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xluDl5cXYy4y"
   },
   "source": [
    "## Scaled dot product attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LazzUq3bJ5SH"
   },
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "  \"\"\"Calculate the attention weights.\n",
    "  q, k, v must have matching leading dimensions.\n",
    "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "  The mask has different shapes depending on its type(padding or look ahead) \n",
    "  but it must be broadcastable for addition.\n",
    "  \n",
    "  Args:\n",
    "    q: query shape == (..., seq_len_q, depth)\n",
    "    k: key shape == (..., seq_len_k, depth)\n",
    "    v: value shape == (..., seq_len_v, depth_v)\n",
    "    mask: Float tensor with shape broadcastable \n",
    "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "    \n",
    "  Returns:\n",
    "    output, attention_weights\n",
    "  \"\"\"\n",
    "\n",
    "  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "  \n",
    "  # scale matmul_qk\n",
    "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "  # add the mask to the scaled tensor.\n",
    "  if mask is not None:\n",
    "    scaled_attention_logits += (mask * -1e9)  \n",
    "\n",
    "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "  # add up to 1.\n",
    "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "  return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FiqETnhCkoXh"
   },
   "source": [
    "As the softmax normalization is done on K, its values decide the amount of importance given to Q.\n",
    "\n",
    "The output represents the multiplication of the attention weights and the V (value) vector. This ensures that the words you want to focus on are kept as-is and the irrelevant words are flushed out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n90YjClyInFy"
   },
   "outputs": [],
   "source": [
    "def print_out(q, k, v):\n",
    "  temp_out, temp_attn = scaled_dot_product_attention(\n",
    "      q, k, v, None)\n",
    "  print ('Attention weights are:')\n",
    "  print (temp_attn)\n",
    "  print ('Output is:')\n",
    "  print (temp_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yAzUAf2DPlNt"
   },
   "outputs": [],
   "source": [
    "# np.set_printoptions(suppress=True)\n",
    "\n",
    "# temp_k = tf.constant([[10,0,0],\n",
    "#                       [0,10,0],\n",
    "#                       [0,0,10],\n",
    "#                       [0,0,10]], dtype=tf.float32)  # (4, 3)\n",
    "\n",
    "# temp_v = tf.constant([[   1,0],\n",
    "#                       [  10,0],\n",
    "#                       [ 100,5],\n",
    "#                       [1000,6]], dtype=tf.float32)  # (4, 2)\n",
    "\n",
    "# # This `query` aligns with the second `key`,\n",
    "# # so the second `value` is returned.\n",
    "# temp_q = tf.constant([[0, 10, 0]], dtype=tf.float32)  # (1, 3)\n",
    "# print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zg6k-fGhgXra"
   },
   "outputs": [],
   "source": [
    "# # This query aligns with a repeated key (third and fourth), \n",
    "# # so all associated values get averaged.\n",
    "# temp_q = tf.constant([[0, 0, 10]], dtype=tf.float32)  # (1, 3)\n",
    "# print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UAq3YOzUgXhb"
   },
   "outputs": [],
   "source": [
    "# # This query aligns equally with the first and second key, \n",
    "# # so their values get averaged.\n",
    "# temp_q = tf.constant([[10, 10, 0]], dtype=tf.float32)  # (1, 3)\n",
    "# print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aOz-4_XIhaTP"
   },
   "source": [
    "Pass all the queries together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6dlU8Tm-hYrF"
   },
   "outputs": [],
   "source": [
    "# temp_q = tf.constant([[0, 0, 10], [0, 10, 0], [10, 10, 0]], dtype=tf.float32)  # (3, 3)\n",
    "# print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kmzGPEy64qmA"
   },
   "source": [
    "## Multi-head attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BSV3PPKsYecw"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads):\n",
    "    super(MultiHeadAttention, self).__init__()\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "    \n",
    "    assert d_model % self.num_heads == 0\n",
    "    \n",
    "    self.depth = d_model // self.num_heads\n",
    "    \n",
    "    self.wq = tf.keras.layers.Dense(d_model)\n",
    "    self.wk = tf.keras.layers.Dense(d_model)\n",
    "    self.wv = tf.keras.layers.Dense(d_model)\n",
    "    \n",
    "    self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "  def split_heads(self, x, batch_size):\n",
    "    \"\"\"Split the last dimension into (num_heads, depth).\n",
    "    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "    \"\"\"\n",
    "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "  def call(self, v, k, q, mask):\n",
    "    batch_size = tf.shape(q)[0]\n",
    "    \n",
    "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "    \n",
    "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "    \n",
    "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "    scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "        q, k, v, mask)\n",
    "    \n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "    concat_attention = tf.reshape(scaled_attention, \n",
    "                                  (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "        \n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hu94p-_-2_BX"
   },
   "outputs": [],
   "source": [
    "# temp_mha = MultiHeadAttention(d_model=512, num_heads=8)\n",
    "# y = tf.random.uniform((1, 60, 512))  # (batch_size, encoder_sequence, d_model)\n",
    "# out, attn = temp_mha(y, k=y, q=y, mask=None)\n",
    "# out.shape, attn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RdDqGayx67vv"
   },
   "source": [
    "## Point wise feed forward network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gBqzJXGfHK3X"
   },
   "source": [
    "Point wise feed forward network consists of two fully-connected layers with a ReLU activation in between."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ET7xLt0yCT6Z"
   },
   "outputs": [],
   "source": [
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "  return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mytb1lPyOHLB"
   },
   "outputs": [],
   "source": [
    "# sample_ffn = point_wise_feed_forward_network(512, 2048)\n",
    "# sample_ffn(tf.random.uniform((64, 50, 512))).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7e7hKcxn6-zd"
   },
   "source": [
    "## Encoder and decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ncyS-Ms3i2x_"
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "    super(EncoderLayer, self).__init__()\n",
    "\n",
    "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    \n",
    "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "  def call(self, x, training, mask):\n",
    "\n",
    "    attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "    attn_output = self.dropout1(attn_output, training=training)\n",
    "    out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "    \n",
    "    ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "    ffn_output = self.dropout2(ffn_output, training=training)\n",
    "    out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "    \n",
    "    return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AzZRXdO0mI48"
   },
   "outputs": [],
   "source": [
    "# sample_encoder_layer = EncoderLayer(512, 8, 2048)\n",
    "\n",
    "# sample_encoder_layer_output = sample_encoder_layer(\n",
    "#     tf.random.uniform((64, 43, 512)), False, None)\n",
    "\n",
    "# sample_encoder_layer_output.shape  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6LO_48Owmx_o"
   },
   "source": [
    "### Decoder layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9SoX0-vd1hue"
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "    super(DecoderLayer, self).__init__()\n",
    "\n",
    "    self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "    self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    " \n",
    "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    \n",
    "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    \n",
    "  def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "    # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "\n",
    "    attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "    attn1 = self.dropout1(attn1, training=training)\n",
    "    out1 = self.layernorm1(attn1 + x)\n",
    "    \n",
    "    attn2, attn_weights_block2 = self.mha2(\n",
    "        enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "    attn2 = self.dropout2(attn2, training=training)\n",
    "    out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "    \n",
    "    ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "    ffn_output = self.dropout3(ffn_output, training=training)\n",
    "    out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "    \n",
    "    return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ne2Bqx8k71l0"
   },
   "outputs": [],
   "source": [
    "# sample_decoder_layer = DecoderLayer(512, 8, 2048)\n",
    "\n",
    "# sample_decoder_layer_output, _, _ = sample_decoder_layer(\n",
    "#     tf.random.uniform((64, 50, 512)), sample_encoder_layer_output, \n",
    "#     False, None, None)\n",
    "\n",
    "# sample_decoder_layer_output.shape  # (batch_size, target_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SE1H51Ajm0q1"
   },
   "source": [
    "### Encoder\n",
    "\n",
    "The `Encoder` consists of:\n",
    "1.   Input Embedding\n",
    "2.   Positional Encoding\n",
    "3.   N encoder layers\n",
    "\n",
    "The input is put through an embedding which is summed with the positional encoding. The output of this summation is the input to the encoder layers. The output of the encoder is the input to the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jpEox7gJ8FCI"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "    super(Encoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "    \n",
    "    self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "    self.pos_encoding = positional_encoding(maximum_position_encoding, \n",
    "                                            self.d_model)\n",
    "    \n",
    "    \n",
    "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
    "                       for _ in range(num_layers)]\n",
    "  \n",
    "    self.dropout = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "  def call(self, x, training, mask):\n",
    "\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    \n",
    "    # adding embedding and position encoding.\n",
    "    x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "    x = self.dropout(x, training=training)\n",
    "    \n",
    "    for i in range(self.num_layers):\n",
    "      x = self.enc_layers[i](x, training, mask)\n",
    "    \n",
    "    return x  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8QG9nueFQKXx"
   },
   "outputs": [],
   "source": [
    "# sample_encoder = Encoder(num_layers=2, d_model=512, num_heads=8, \n",
    "#                          dff=2048, input_vocab_size=8500,\n",
    "#                          maximum_position_encoding=10000)\n",
    "# temp_input = tf.random.uniform((64, 62), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "# sample_encoder_output = sample_encoder(temp_input, training=False, mask=None)\n",
    "\n",
    "# print (sample_encoder_output.shape)  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p-uO6ls8m2O5"
   },
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZtT7PKzrXkNr"
   },
   "source": [
    " The `Decoder` consists of:\n",
    "1.   Output Embedding\n",
    "2.   Positional Encoding\n",
    "3.   N decoder layers\n",
    "\n",
    "The target is put through an embedding which is summed with the positional encoding. The output of this summation is the input to the decoder layers. The output of the decoder is the input to the final linear layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d5_d5-PLQXwY"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "    super(Decoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "    \n",
    "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "    self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "    \n",
    "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n",
    "                       for _ in range(num_layers)]\n",
    "    self.dropout = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "  def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    attention_weights = {}\n",
    "    \n",
    "    x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x += self.pos_encoding[:, :seq_len, :]\n",
    "    \n",
    "    x = self.dropout(x, training=training)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
    "                                             look_ahead_mask, padding_mask)\n",
    "      \n",
    "      attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "      attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "    \n",
    "    # x.shape == (batch_size, target_seq_len, d_model)\n",
    "    return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a1jXoAMRZyvu"
   },
   "outputs": [],
   "source": [
    "# sample_decoder = Decoder(num_layers=2, d_model=512, num_heads=8, \n",
    "#                          dff=2048, target_vocab_size=8000,\n",
    "#                          maximum_position_encoding=5000)\n",
    "# temp_input = tf.random.uniform((64, 26), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "# output, attn = sample_decoder(temp_input, \n",
    "#                               enc_output=sample_encoder_output, \n",
    "#                               training=False,\n",
    "#                               look_ahead_mask=None, \n",
    "#                               padding_mask=None)\n",
    "\n",
    "# output.shape, attn['decoder_layer2_block2'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y54xnJnuYgJ7"
   },
   "source": [
    "## Create the Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uERO1y54cOKq"
   },
   "source": [
    "Transformer consists of the encoder, decoder and a final linear layer. The output of the decoder is the input to the linear layer and its output is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PED3bIpOYkBu"
   },
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
    "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "    super(Transformer, self).__init__()\n",
    "\n",
    "    self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n",
    "                           input_vocab_size, pe_input, rate)\n",
    "\n",
    "    self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n",
    "                           target_vocab_size, pe_target, rate)\n",
    "\n",
    "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "    \n",
    "  def call(self, inp, tar, training, enc_padding_mask, \n",
    "           look_ahead_mask, dec_padding_mask):\n",
    "\n",
    "    enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
    "    \n",
    "    # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "    dec_output, attention_weights = self.decoder(\n",
    "        tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "    \n",
    "    final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "    \n",
    "    return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tJ4fbQcIkHW1"
   },
   "outputs": [],
   "source": [
    "# sample_transformer = Transformer(\n",
    "#     num_layers=2, d_model=512, num_heads=8, dff=2048, \n",
    "#     input_vocab_size=8500, target_vocab_size=8000, \n",
    "#     pe_input=10000, pe_target=6000)\n",
    "\n",
    "# temp_input = tf.random.uniform((64, 38), dtype=tf.int64, minval=0, maxval=200)\n",
    "# temp_target = tf.random.uniform((64, 36), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "# fn_out, _ = sample_transformer(temp_input, temp_target, training=False, \n",
    "#                                enc_padding_mask=None, \n",
    "#                                look_ahead_mask=None,\n",
    "#                                dec_padding_mask=None)\n",
    "\n",
    "# fn_out.shape  # (batch_size, tar_seq_len, target_vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wsINyf1VEQLC"
   },
   "source": [
    "## Set hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zVjWCxFNcgbt"
   },
   "source": [
    "To keep this example small and relatively fast, the values for *num_layers, d_model, and dff* have been reduced. \n",
    "\n",
    "The values used in the base model of transformer were; *num_layers=6*, *d_model = 512*, *dff = 2048*. See the [paper](https://arxiv.org/abs/1706.03762) for all the other versions of the transformer.\n",
    "\n",
    "Note: By changing the values below, you can get the model that achieved state of the art on many tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lnJn5SLA2ahP"
   },
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "\n",
    "input_vocab_size = tokenizer_pt.vocab_size + 2\n",
    "target_vocab_size = tokenizer_en.vocab_size + 2\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GiMn_VdlaYLg"
   },
   "outputs": [],
   "source": [
    "# # PAPER HYPERPARAMETERS\n",
    "# num_layers = 6\n",
    "# d_model = 512\n",
    "# dff = 2048\n",
    "# num_heads = 8\n",
    "\n",
    "# input_vocab_size = tokenizer_pt.vocab_size + 2\n",
    "# target_vocab_size = tokenizer_en.vocab_size + 2\n",
    "# dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xYEGhEOtzn5W"
   },
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GOmWW--yP3zx"
   },
   "source": [
    "Use the Adam optimizer with a custom learning rate scheduler according to the formula in the [paper](https://arxiv.org/abs/1706.03762).\n",
    "\n",
    "$$\\Large{lrate = d_{model}^{-0.5} * min(step{\\_}num^{-0.5}, step{\\_}num * warmup{\\_}steps^{-1.5})}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iYQdOO1axwEI"
   },
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "    \n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "    \n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps ** -1.5)\n",
    "    \n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7r4scdulztRx"
   },
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
    "                                     epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f33ZCgvHpPdG"
   },
   "outputs": [],
   "source": [
    "# temp_learning_rate_schedule = CustomSchedule(d_model)\n",
    "\n",
    "# plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))\n",
    "# plt.ylabel(\"Learning Rate\")\n",
    "# plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YgkDE7hzo8r5"
   },
   "source": [
    "## Loss and metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oxGJtoDuYIHL"
   },
   "source": [
    "Since the target sequences are padded, it is important to apply a padding mask when calculating the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MlhsJMm0TW_B"
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "67oqVHiT0Eiu"
   },
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "  \n",
    "  return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "phlyxMnm-Tpx"
   },
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "    name='train_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aeHumfr7zmMa"
   },
   "source": [
    "## Training and checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UiysUa--4tOU"
   },
   "outputs": [],
   "source": [
    "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
    "                          input_vocab_size, target_vocab_size, \n",
    "                          pe_input=input_vocab_size, \n",
    "                          pe_target=target_vocab_size,\n",
    "                          rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MgnBWEZ0hFbZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.encoder.d_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZOJUSB1T8GjM"
   },
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "  # Encoder padding mask\n",
    "  enc_padding_mask = create_padding_mask(inp)\n",
    "  \n",
    "  # Used in the 2nd attention block in the decoder.\n",
    "  # This padding mask is used to mask the encoder outputs.\n",
    "  dec_padding_mask = create_padding_mask(inp)\n",
    "  \n",
    "  # Used in the 1st attention block in the decoder.\n",
    "  # It is used to pad and mask future tokens in the input received by \n",
    "  # the decoder.\n",
    "  look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "  dec_target_padding_mask = create_padding_mask(tar)\n",
    "  combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "  \n",
    "  return enc_padding_mask, combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fzuf06YZp66w"
   },
   "source": [
    "Create the checkpoint path and the checkpoint manager. This will be used to save checkpoints every `n` epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hNhuYfllndLZ"
   },
   "outputs": [],
   "source": [
    "checkpoint_path = \"checkpoints/train\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
    "                           optimizer=optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "  ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "  print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Di_Yaa1gf9r"
   },
   "source": [
    "The target is divided into tar_inp and tar_real. tar_inp is passed as an input to the decoder. `tar_real` is that same input shifted by 1: At each location in `tar_input`, `tar_real` contains the  next token that should be predicted.\n",
    "\n",
    "For example, `sentence` = \"SOS A lion in the jungle is sleeping EOS\"\n",
    "\n",
    "`tar_inp` =  \"SOS A lion in the jungle is sleeping\"\n",
    "\n",
    "`tar_real` = \"A lion in the jungle is sleeping EOS\"\n",
    "\n",
    "The transformer is an auto-regressive model: it makes predictions one part at a time, and uses its output so far to decide what to do next. \n",
    "\n",
    "During training this example uses teacher-forcing (like in the [text generation tutorial](./text_generation.ipynb)). Teacher forcing is passing the true output to the next time step regardless of what the model predicts at the current time step.\n",
    "\n",
    "As the transformer predicts each word, *self-attention* allows it to look at the previous words in the input sequence to better predict the next word.\n",
    "\n",
    "To prevent the model from peaking at the expected output the model uses a look-ahead mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LKpoA6q1sJFj"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iJwmp9OE29oj"
   },
   "outputs": [],
   "source": [
    "# The @tf.function trace-compiles train_step into a TF graph for faster\n",
    "# execution. The function specializes to the precise shape of the argument\n",
    "# tensors. To avoid re-tracing due to the variable sequence lengths or variable\n",
    "# batch sizes (the last batch is smaller), use input_signature to specify\n",
    "# more generic shapes.\n",
    "\n",
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "]\n",
    "\n",
    "@tf.function(input_signature=train_step_signature)\n",
    "def train_step(inp, tar):\n",
    "  tar_inp = tar[:, :-1]\n",
    "  tar_real = tar[:, 1:]\n",
    "  \n",
    "  enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "  \n",
    "  with tf.GradientTape() as tape:\n",
    "    predictions, _ = transformer(inp, tar_inp, \n",
    "                                 True, \n",
    "                                 enc_padding_mask, \n",
    "                                 combined_mask, \n",
    "                                 dec_padding_mask)\n",
    "    loss = loss_function(tar_real, predictions)\n",
    "\n",
    "  gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
    "  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "  \n",
    "  train_loss(loss)\n",
    "  train_accuracy(tar_real, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qM2PDWGDJ_8V"
   },
   "source": [
    "Portuguese is used as the input language and English is the target language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bbvmaKNiznHZ",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 5.3179 Accuracy 0.0000\n",
      "Epoch 1 Batch 50 Loss 5.1245 Accuracy 0.0007\n",
      "Epoch 1 Batch 100 Loss 5.0493 Accuracy 0.0121\n",
      "Epoch 1 Batch 150 Loss 4.9640 Accuracy 0.0179\n",
      "\n",
      "Epoch 1 Batch 200 Loss 4.9049 Accuracy 0.0213\n",
      "Epoch 1 Batch 250 Loss 4.8280 Accuracy 0.0248\n",
      "Epoch 1 Batch 300 Loss 4.7325 Accuracy 0.0288\n",
      "Epoch 1 Batch 350 Loss 4.6301 Accuracy 0.0339\n",
      "Epoch 1 Batch 400 Loss 4.5354 Accuracy 0.0387\n",
      "Epoch 1 Batch 450 Loss 4.4469 Accuracy 0.0427\n",
      "Epoch 1 Batch 500 Loss 4.3617 Accuracy 0.0468\n",
      "Epoch 1 Loss 4.3543 Accuracy 0.0472\n",
      "Time taken for 1 epoch: 429.6082499027252 secs\n",
      "\n",
      "Epoch 2 Batch 0 Loss 3.6000 Accuracy 0.0861\n",
      "Epoch 2 Batch 50 Loss 3.5589 Accuracy 0.0938\n",
      "Epoch 2 Batch 100 Loss 3.4928 Accuracy 0.0976\n",
      "Epoch 2 Batch 150 Loss 3.4432 Accuracy 0.1009\n",
      "Epoch 2 Batch 200 Loss 3.3948 Accuracy 0.1043\n",
      "Epoch 2 Batch 250 Loss 3.3360 Accuracy 0.1073\n",
      "Epoch 2 Batch 300 Loss 3.2924 Accuracy 0.1102\n",
      "Epoch 2 Batch 350 Loss 3.2560 Accuracy 0.1132\n",
      "Epoch 2 Batch 400 Loss 3.2203 Accuracy 0.1157\n",
      "Epoch 2 Batch 450 Loss 3.1881 Accuracy 0.1182\n",
      "Epoch 2 Batch 500 Loss 3.1576 Accuracy 0.1206\n",
      "Epoch 2 Loss 3.1546 Accuracy 0.1208\n",
      "Time taken for 1 epoch: 508.1735608577728 secs\n",
      "\n",
      "Epoch 3 Batch 0 Loss 2.6967 Accuracy 0.1466\n",
      "Epoch 3 Batch 50 Loss 2.8358 Accuracy 0.1469\n",
      "Epoch 3 Batch 100 Loss 2.8165 Accuracy 0.1470\n",
      "Epoch 3 Batch 150 Loss 2.8147 Accuracy 0.1480\n",
      "Epoch 3 Batch 200 Loss 2.8061 Accuracy 0.1490\n",
      "Epoch 3 Batch 250 Loss 2.7812 Accuracy 0.1499\n",
      "Epoch 3 Batch 300 Loss 2.7709 Accuracy 0.1512\n",
      "Epoch 3 Batch 350 Loss 2.7631 Accuracy 0.1524\n",
      "Epoch 3 Batch 400 Loss 2.7522 Accuracy 0.1536\n",
      "Epoch 3 Batch 450 Loss 2.7423 Accuracy 0.1545\n",
      "Epoch 3 Batch 500 Loss 2.7298 Accuracy 0.1554\n",
      "Epoch 3 Loss 2.7307 Accuracy 0.1555\n",
      "Time taken for 1 epoch: 375.77764987945557 secs\n",
      "\n",
      "Epoch 4 Batch 0 Loss 2.3700 Accuracy 0.1530\n",
      "Epoch 4 Batch 50 Loss 2.5652 Accuracy 0.1665\n",
      "Epoch 4 Batch 100 Loss 2.5757 Accuracy 0.1674\n",
      "Epoch 4 Batch 150 Loss 2.5758 Accuracy 0.1688\n",
      "Epoch 4 Batch 200 Loss 2.5688 Accuracy 0.1695\n",
      "Epoch 4 Batch 250 Loss 2.5600 Accuracy 0.1701\n",
      "Epoch 4 Batch 300 Loss 2.5548 Accuracy 0.1708\n",
      "Epoch 4 Batch 350 Loss 2.5466 Accuracy 0.1713\n",
      "Epoch 4 Batch 400 Loss 2.5400 Accuracy 0.1718\n",
      "Epoch 4 Batch 450 Loss 2.5300 Accuracy 0.1723\n",
      "Epoch 4 Batch 500 Loss 2.5223 Accuracy 0.1729\n",
      "Epoch 4 Loss 2.5218 Accuracy 0.1730\n",
      "Time taken for 1 epoch: 377.37636494636536 secs\n",
      "\n",
      "Epoch 5 Batch 0 Loss 2.4920 Accuracy 0.1854\n",
      "Epoch 5 Batch 50 Loss 2.3952 Accuracy 0.1818\n",
      "Epoch 5 Batch 100 Loss 2.3878 Accuracy 0.1826\n",
      "Epoch 5 Batch 150 Loss 2.3787 Accuracy 0.1832\n",
      "Epoch 5 Batch 200 Loss 2.3773 Accuracy 0.1835\n",
      "Epoch 5 Batch 250 Loss 2.3736 Accuracy 0.1842\n",
      "Epoch 5 Batch 300 Loss 2.3718 Accuracy 0.1842\n",
      "Epoch 5 Batch 350 Loss 2.3696 Accuracy 0.1845\n",
      "Epoch 5 Batch 400 Loss 2.3648 Accuracy 0.1846\n",
      "Epoch 5 Batch 450 Loss 2.3623 Accuracy 0.1850\n",
      "Epoch 5 Batch 500 Loss 2.3608 Accuracy 0.1855\n",
      "Saving checkpoint for epoch 5 at checkpoints/train/ckpt-1\n",
      "Epoch 5 Loss 2.3611 Accuracy 0.1855\n",
      "Time taken for 1 epoch: 369.0688579082489 secs\n",
      "\n",
      "Epoch 6 Batch 0 Loss 2.3648 Accuracy 0.1935\n",
      "Epoch 6 Batch 50 Loss 2.2233 Accuracy 0.1959\n",
      "Epoch 6 Batch 100 Loss 2.2535 Accuracy 0.1973\n",
      "Epoch 6 Batch 150 Loss 2.2392 Accuracy 0.1965\n",
      "Epoch 6 Batch 200 Loss 2.2297 Accuracy 0.1961\n",
      "Epoch 6 Batch 250 Loss 2.2260 Accuracy 0.1962\n",
      "Epoch 6 Batch 300 Loss 2.2241 Accuracy 0.1959\n",
      "Epoch 6 Batch 350 Loss 2.2222 Accuracy 0.1962\n",
      "Epoch 6 Batch 400 Loss 2.2209 Accuracy 0.1966\n",
      "Epoch 6 Batch 450 Loss 2.2219 Accuracy 0.1968\n",
      "Epoch 6 Batch 500 Loss 2.2155 Accuracy 0.1972\n",
      "Epoch 6 Loss 2.2157 Accuracy 0.1972\n",
      "Time taken for 1 epoch: 362.1720447540283 secs\n",
      "\n",
      "Epoch 7 Batch 0 Loss 2.0631 Accuracy 0.2047\n",
      "Epoch 7 Batch 50 Loss 2.0691 Accuracy 0.2105\n",
      "Epoch 7 Batch 100 Loss 2.0718 Accuracy 0.2096\n",
      "Epoch 7 Batch 150 Loss 2.0799 Accuracy 0.2105\n",
      "Epoch 7 Batch 200 Loss 2.0769 Accuracy 0.2110\n",
      "Epoch 7 Batch 250 Loss 2.0680 Accuracy 0.2104\n",
      "Epoch 7 Batch 300 Loss 2.0710 Accuracy 0.2108\n",
      "Epoch 7 Batch 350 Loss 2.0657 Accuracy 0.2109\n",
      "Epoch 7 Batch 400 Loss 2.0678 Accuracy 0.2112\n",
      "Epoch 7 Batch 450 Loss 2.0652 Accuracy 0.2113\n",
      "Epoch 7 Batch 500 Loss 2.0684 Accuracy 0.2119\n",
      "Epoch 7 Loss 2.0678 Accuracy 0.2119\n",
      "Time taken for 1 epoch: 374.4852149486542 secs\n",
      "\n",
      "Epoch 8 Batch 0 Loss 1.8588 Accuracy 0.2323\n",
      "Epoch 8 Batch 50 Loss 1.9147 Accuracy 0.2254\n",
      "Epoch 8 Batch 100 Loss 1.9154 Accuracy 0.2253\n",
      "Epoch 8 Batch 150 Loss 1.9243 Accuracy 0.2260\n",
      "Epoch 8 Batch 200 Loss 1.9210 Accuracy 0.2253\n",
      "Epoch 8 Batch 250 Loss 1.9204 Accuracy 0.2253\n",
      "Epoch 8 Batch 300 Loss 1.9211 Accuracy 0.2251\n",
      "Epoch 8 Batch 350 Loss 1.9264 Accuracy 0.2253\n",
      "Epoch 8 Batch 400 Loss 1.9262 Accuracy 0.2254\n",
      "Epoch 8 Batch 450 Loss 1.9265 Accuracy 0.2256\n",
      "Epoch 8 Batch 500 Loss 1.9284 Accuracy 0.2257\n",
      "Epoch 8 Loss 1.9300 Accuracy 0.2257\n",
      "Time taken for 1 epoch: 396.97506499290466 secs\n",
      "\n",
      "Epoch 9 Batch 0 Loss 1.7301 Accuracy 0.2228\n",
      "Epoch 9 Batch 50 Loss 1.7721 Accuracy 0.2395\n",
      "Epoch 9 Batch 100 Loss 1.7858 Accuracy 0.2407\n",
      "Epoch 9 Batch 150 Loss 1.7957 Accuracy 0.2407\n",
      "Epoch 9 Batch 200 Loss 1.7956 Accuracy 0.2405\n",
      "Epoch 9 Batch 250 Loss 1.7902 Accuracy 0.2405\n",
      "Epoch 9 Batch 300 Loss 1.7901 Accuracy 0.2402\n",
      "Epoch 9 Batch 350 Loss 1.7957 Accuracy 0.2403\n",
      "Epoch 9 Batch 400 Loss 1.7942 Accuracy 0.2404\n",
      "Epoch 9 Batch 450 Loss 1.7961 Accuracy 0.2404\n",
      "Epoch 9 Batch 500 Loss 1.7937 Accuracy 0.2403\n",
      "Epoch 9 Loss 1.7928 Accuracy 0.2402\n",
      "Time taken for 1 epoch: 399.38680696487427 secs\n",
      "\n",
      "Epoch 10 Batch 0 Loss 1.7763 Accuracy 0.2817\n",
      "Epoch 10 Batch 50 Loss 1.6325 Accuracy 0.2585\n",
      "Epoch 10 Batch 100 Loss 1.6342 Accuracy 0.2598\n",
      "Epoch 10 Batch 150 Loss 1.6435 Accuracy 0.2585\n",
      "Epoch 10 Batch 200 Loss 1.6485 Accuracy 0.2580\n",
      "Epoch 10 Batch 250 Loss 1.6516 Accuracy 0.2576\n",
      "Epoch 10 Batch 300 Loss 1.6498 Accuracy 0.2566\n",
      "Epoch 10 Batch 350 Loss 1.6576 Accuracy 0.2563\n",
      "Epoch 10 Batch 400 Loss 1.6611 Accuracy 0.2563\n",
      "Epoch 10 Batch 450 Loss 1.6625 Accuracy 0.2556\n",
      "Epoch 10 Batch 500 Loss 1.6624 Accuracy 0.2554\n",
      "Saving checkpoint for epoch 10 at checkpoints/train/ckpt-2\n",
      "Epoch 10 Loss 1.6622 Accuracy 0.2554\n",
      "Time taken for 1 epoch: 402.072527885437 secs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "  \n",
    "  train_loss.reset_states()\n",
    "  train_accuracy.reset_states()\n",
    "  \n",
    "  # inp -> portuguese, tar -> english\n",
    "  for (batch, (inp, tar)) in enumerate(train_dataset):\n",
    "    train_step(inp, tar)\n",
    "    \n",
    "    if batch % 50 == 0:\n",
    "      print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
    "          epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
    "      \n",
    "  if (epoch + 1) % 5 == 0:\n",
    "    ckpt_save_path = ckpt_manager.save()\n",
    "    print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
    "                                                         ckpt_save_path))\n",
    "    \n",
    "  print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
    "                                                train_loss.result(), \n",
    "                                                train_accuracy.result()))\n",
    "\n",
    "  print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4IxZOvQyZsYz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UN4rIe7yZsMv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QfcsSWswSdGV"
   },
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y6APsFrgImLW"
   },
   "source": [
    "The following steps are used for evaluation:\n",
    "\n",
    "* Encode the input sentence using the Portuguese tokenizer (`tokenizer_pt`). Moreover, add the start and end token so the input is equivalent to what the model is trained with. This is the encoder input.\n",
    "* The decoder input is the `start token == tokenizer_en.vocab_size`.\n",
    "* Calculate the padding masks and the look ahead masks.\n",
    "* The `decoder` then outputs the predictions by looking at the `encoder output` and its own output (self-attention).\n",
    "* Select the last word and calculate the argmax of that.\n",
    "* Concatentate the predicted word to the decoder input as pass it to the decoder.\n",
    "* In this approach, the decoder predicts the next word based on the previous words it predicted.\n",
    "\n",
    "Note: The model used here has less capacity to keep the example relatively faster so the predictions maybe less right. To reproduce the results in the paper, use the entire dataset and base transformer model or transformer XL, by changing the hyperparameters above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5buvMlnvyrFm"
   },
   "outputs": [],
   "source": [
    "def evaluate(inp_sentence):\n",
    "  start_token = [tokenizer_pt.vocab_size]\n",
    "  end_token = [tokenizer_pt.vocab_size + 1]\n",
    "  \n",
    "  # inp sentence is portuguese, hence adding the start and end token\n",
    "  inp_sentence = start_token + tokenizer_pt.encode(inp_sentence) + end_token\n",
    "  encoder_input = tf.expand_dims(inp_sentence, 0)\n",
    "  \n",
    "  # as the target is english, the first word to the transformer should be the\n",
    "  # english start token.\n",
    "  decoder_input = [tokenizer_en.vocab_size]\n",
    "  output = tf.expand_dims(decoder_input, 0)\n",
    "    \n",
    "  for i in range(MAX_LENGTH):\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
    "        encoder_input, output)\n",
    "  \n",
    "    # predictions.shape == (batch_size, seq_len, vocab_size)\n",
    "    predictions, attention_weights = transformer(encoder_input, \n",
    "                                                 output,\n",
    "                                                 False,\n",
    "                                                 enc_padding_mask,\n",
    "                                                 combined_mask,\n",
    "                                                 dec_padding_mask)\n",
    "    \n",
    "    # select the last word from the seq_len dimension\n",
    "    predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
    "\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "    \n",
    "    # return the result if the predicted_id is equal to the end token\n",
    "    if predicted_id == tokenizer_en.vocab_size+1:\n",
    "      return tf.squeeze(output, axis=0), attention_weights\n",
    "    \n",
    "    # concatentate the predicted_id to the output which is given to the decoder\n",
    "    # as its input.\n",
    "    output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output, axis=0), attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CN-BV43FMBej"
   },
   "outputs": [],
   "source": [
    "def plot_attention_weights(attention, sentence, result, layer):\n",
    "  fig = plt.figure(figsize=(16, 8))\n",
    "  \n",
    "  sentence = tokenizer_pt.encode(sentence)\n",
    "  \n",
    "  attention = tf.squeeze(attention[layer], axis=0)\n",
    "  \n",
    "  for head in range(attention.shape[0]):\n",
    "    ax = fig.add_subplot(2, 4, head+1)\n",
    "    \n",
    "    # plot the attention weights\n",
    "    ax.matshow(attention[head][:-1, :], cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 10}\n",
    "    \n",
    "    ax.set_xticks(range(len(sentence)+2))\n",
    "    ax.set_yticks(range(len(result)))\n",
    "    \n",
    "    ax.set_ylim(len(result)-1.5, -0.5)\n",
    "        \n",
    "    ax.set_xticklabels(\n",
    "        ['<start>']+[tokenizer_pt.decode([i]) for i in sentence]+['<end>'], \n",
    "        fontdict=fontdict, rotation=90)\n",
    "    \n",
    "    ax.set_yticklabels([tokenizer_en.decode([i]) for i in result \n",
    "                        if i < tokenizer_en.vocab_size], \n",
    "                       fontdict=fontdict)\n",
    "    \n",
    "    ax.set_xlabel('Head {}'.format(head+1))\n",
    "  \n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lU2_yG_vBGza"
   },
   "outputs": [],
   "source": [
    "def translate(sentence, plot=''):\n",
    "  result, attention_weights = evaluate(sentence)\n",
    "  \n",
    "  predicted_sentence = tokenizer_en.decode([i for i in result \n",
    "                                            if i < tokenizer_en.vocab_size])  \n",
    "\n",
    "  print('Input: {}'.format(sentence))\n",
    "  print('Predicted translation: {}'.format(predicted_sentence))\n",
    "  \n",
    "  if plot:\n",
    "    plot_attention_weights(attention_weights, sentence, result, plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rt-URn_gVLWo"
   },
   "outputs": [],
   "source": [
    "stmts = [\n",
    "  'Und zwar sollen derartige Strafen trotz des Grundsatzes der relativen Stabilität verhängt werden .',\n",
    "  'Wiederaufnahme der Sitzungsperiode',\n",
    "  'Der Arbeitsminister der Vereinigten Staaten , Thomas E. Perez',\n",
    "  'Unsere Verpflichtung gegenüber Bangladesch ist stark und auf Dauer angelegt .',\n",
    "  'Der Außenminister der Vereinigten Staaten , John Kerry',\n",
    "  'Die Hohe Vertreterin der Europäischen Union für Außen- und Sicherheitspolitik / Vizepräsidentin der Kommission , Federica Mogherini',\n",
    "]\n",
    "\n",
    "for stmt in stmts:\n",
    "  translate(stmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j1Kbm1YLVI2G"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q0ErTon8VItd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q3JRt2drVIhz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YsxrAlvFG8SZ"
   },
   "outputs": [],
   "source": [
    "translate(\"este é um problema que temos que resolver.\")\n",
    "print (\"Real translation: this is a problem we have to solve .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7EH5y_aqI4t1"
   },
   "outputs": [],
   "source": [
    "translate(\"os meus vizinhos ouviram sobre esta ideia.\")\n",
    "print (\"Real translation: and my neighboring homes heard about this idea .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J-hVCTSUMlkb"
   },
   "outputs": [],
   "source": [
    "translate(\"vou então muito rapidamente partilhar convosco algumas histórias de algumas coisas mágicas que aconteceram.\")\n",
    "print (\"Real translation: so i 'll just share with you some stories very quickly of some magical things that have happened .\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_1MxkSZvz0jX"
   },
   "source": [
    "You can pass different layers and attention blocks of the decoder to the `plot` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t-kFyiOLH0xg"
   },
   "outputs": [],
   "source": [
    "translate(\"este é o primeiro livro que eu fiz.\", plot='decoder_layer4_block2')\n",
    "print (\"Real translation: this is the first book i've ever done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RqQ1fIsLwkGE"
   },
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, you learned about positional encoding, multi-head attention, the importance of masking and how to create a transformer.\n",
    "\n",
    "Try using a different dataset to train the transformer. You can also create the base transformer or transformer XL by changing the hyperparameters above. You can also use the layers defined here to create [BERT](https://arxiv.org/abs/1810.04805) and train state of the art models. Futhermore, you can implement beam search to get better predictions."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "s_qNSzzyaCbD"
   ],
   "name": "Transformer with Noise Data.ipynb",
   "private_outputs": true,
   "provenance": [
    {
     "file_id": "https://github.com/tensorflow/docs/blob/master/site/en/tutorials/text/transformer.ipynb",
     "timestamp": 1585523383772
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
